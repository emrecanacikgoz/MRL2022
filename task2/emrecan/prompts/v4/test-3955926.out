Setting stack size to unlimited...
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 2061307
max locked memory       (kbytes, -l) unlimited
max memory size         (kbytes, -m) 20971520
open files                      (-n) 51200
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) unlimited
cpu time               (seconds, -t) unlimited
max user processes              (-u) 4096
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

Mon Aug  8 12:33:50 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:3D:00.0 Off |                    0 |
| N/A   31C    P0    25W /  70W |      0MiB / 15109MiB |      5%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Using pad_token, but it is not set yet.
Namespace(lang='eng', lr=5e-05, model='gpt2', model_name_or_path='sberbank-ai/mGPT', plm_eval_mode=False, run=3)
{
  "guid": 0,
  "label": null,
  "meta": {},
  "text_a": "will he be abusing her?:COND,PROG,NOM(3,PL),NEG,Q,ACC(3,SG,FEM)",
  "text_b": "",
  "tgt_text": "wouldn't they be abusing her?"
}

[[{'text': 'will he be abusing her?:COND,PROG,NOM(3,PL),NEG,Q,ACC(3,SG,FEM)', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': "wouldn't they be abusing her?"}]
tokenizing: 0it [00:00, ?it/s]tokenizing: 110it [00:00, 1095.36it/s]tokenizing: 331it [00:00, 1745.94it/s]tokenizing: 560it [00:00, 1993.23it/s]tokenizing: 789it [00:00, 2108.33it/s]tokenizing: 1014it [00:00, 2157.44it/s]tokenizing: 1243it [00:00, 2202.28it/s]tokenizing: 1464it [00:00, 2192.90it/s]tokenizing: 1684it [00:00, 2194.74it/s]tokenizing: 1904it [00:00, 2182.17it/s]tokenizing: 2133it [00:01, 2213.79it/s]tokenizing: 2365it [00:01, 2243.87it/s]tokenizing: 2592it [00:01, 2250.56it/s]tokenizing: 2818it [00:01, 2228.48it/s]tokenizing: 3041it [00:01, 2208.62it/s]tokenizing: 3270it [00:01, 2231.27it/s]tokenizing: 3495it [00:01, 2234.68it/s]tokenizing: 3719it [00:01, 2231.19it/s]tokenizing: 3943it [00:01, 1728.61it/s]tokenizing: 4160it [00:02, 1836.74it/s]tokenizing: 4374it [00:02, 1914.19it/s]tokenizing: 4589it [00:02, 1976.62it/s]tokenizing: 4817it [00:02, 2061.17it/s]tokenizing: 5041it [00:02, 2110.53it/s]tokenizing: 5257it [00:02, 2096.55it/s]tokenizing: 5472it [00:02, 2109.92it/s]tokenizing: 5686it [00:02, 2112.97it/s]tokenizing: 5909it [00:02, 2145.66it/s]tokenizing: 6137it [00:02, 2183.67it/s]tokenizing: 6359it [00:03, 2192.94it/s]tokenizing: 6579it [00:03, 2160.18it/s]tokenizing: 6796it [00:03, 2155.89it/s]tokenizing: 7013it [00:03, 2158.63it/s]tokenizing: 7230it [00:03, 2149.94it/s]tokenizing: 7455it [00:03, 2178.28it/s]tokenizing: 7683it [00:03, 2205.86it/s]tokenizing: 7904it [00:03, 2198.08it/s]tokenizing: 8124it [00:03, 2187.82it/s]tokenizing: 8352it [00:03, 2215.06it/s]tokenizing: 8585it [00:04, 2248.03it/s]tokenizing: 8819it [00:04, 2273.19it/s]tokenizing: 9047it [00:04, 2273.19it/s]tokenizing: 9275it [00:04, 2255.50it/s]tokenizing: 9504it [00:04, 2265.65it/s]tokenizing: 9735it [00:04, 2278.48it/s]tokenizing: 9963it [00:04, 2272.78it/s]tokenizing: 10000it [00:04, 2148.72it/s]
tokenizing: 0it [00:00, ?it/s]tokenizing: 391it [00:00, 3909.32it/s]tokenizing: 782it [00:00, 3838.17it/s]tokenizing: 1000it [00:00, 3851.46it/s]
tokenizing: 0it [00:00, ?it/s]tokenizing: 398it [00:00, 3978.29it/s]tokenizing: 796it [00:00, 3923.13it/s]tokenizing: 1000it [00:00, 3942.73it/s]Epoch 0, global_step 500 average loss: 6.227458426058292 lr: 4.2e-05
